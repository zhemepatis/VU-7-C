\section{Praktinė dalis}

    Siekiant įvertinti, kaip dirbtiniai neuroniniai tinklai reaguoja į triukšmą duomenyse, buvo atlikti bandymai su sukurtu dirbtinio neuroninio tinklo modeliu (\ref{} skyrius). Papildomai, norint įvertinti, kiek geriau dirbtinis neuroninis tinklas susitvarko su triukšmu duomenyse, tam pačiam uždaviniui buvo pritaikyti ir keli k artimiausių kaimynų modeliai (\ref{} skyrius). Visi modeliai buvo pritaikyti tiek su švariom duomenų aibėm, tiek su aibėm, kuriose yra pritaikytas tam tikras triukšmo lygis.
        
    % TODO: move somwhere else
    % Prieš pereinant prie vėlesniuose skyreliuose aptariamų tyrimų ir juose rastų rezultatų, pravartu aptarti juose vartojamas sąvokas. Šio darbo kontekste laikysime, kad \enquote{epocha} tai yra modelio perėjimas per visą apmokymo duomenų aibę, o \enquote{iteracija} yra modelio svertų atnaujinimas.

    \subsection{Duomenų aibės kūrimas}

        Bandymams atlikti buvo generuojami keturmačiai duomenys, kurių kiekviena komponentė buvo parenkama iš intervalo $[-5; 5]$. Duomenų generavimui buvo pasitelktos sferos (\ref{eq:sferos_etalono_funkc} lygtis), ... (\ref{} lygtis) bei ... (\ref{} lygtis) etalono funkcijos. 
        
        Mašininio mokymosi modeliai buvo pritaikyti skirtingo dydžio kiekvienos rūšies duomenų aibėms. Dirbtinis neuroninis tinklas buvo pritaikytas su 1~000, 10~000, 100~000, 1~000~000 dydžio duomenų aibėmis, tuo tarpu k artimiausių kaimynų metodas dar papildomai buvo išbandytas su aibe, turinčia 10~000~000 įrašų. 
        
        Triukšmo pridėjimui į duomenų aibę buvo pasitelktas Gauso paskirsymo funkcijos metodas (\ref{} skyrius). Paklaidos buvo pridedamos prie sugeneruotų etalono funkcijų reikšmių. Triukšmas buvo generuojamos su parametrais $\mu = 0$, $\sigma = 0.5$.

        Taip pat verta paminėti, kad prieš apmokant modelius duomenys dar papildomai buvo normalizuojami pasitelkiant min-max metodą. Šis metodas leidžia skaitines reikšmes sutraukti į intervalą $[0; 1]$ taip išvengiant skirtingų požymių mastelių įtakos mokymo procesui. Tai yra atliekama pasitelkiant formulę

        \begin{equation}
            \label{eq:min_max_funkc}
            x' = \frac{x - \min(x)}{\max(x) - \min(x)}
        \end{equation}

    \input{skyriai/praktine_dalis/fnn}

    \subsection{K artimiausių kaimynų metodo rezultatai}

        Tyrimas buvo atliktas su 1~000, 10~000, 100~000, 1~000~000 ir 10~000~000 taškų aibėmis, kurių $85\%$ buvo skiriami modelio apmokymui ir validavimui, likę $15\%$ - modelio testavimui.

        Bandymui buvo generuojami keturmačiai duomenys ($n = 4$), kurių kiekviena komponentė buvo atsitiktinai parenkama iš intervalo $[-5; 5]$. Prieš apmokant modelį, duomenys buvo papildomai apdorojami: kiekviena vektoriaus komponentė bei sferos funkcijos reikšmės buvo normalizuojamos naudojant min–max metodą.

        Modelis buvo validuojamas pasitelkiant kryžminę validaciją (angl. \textit{cross-validation}). Bandymų metu buvo nustatyta, kad geriausiai modelis veikia, kai kaimynų skaičius yra lygus $3$, tačiau palyginimui buvo atlikti bandymai ir kai artimiausias kaimynas yra vienas.

        Visais atvejais prieš skaičiuojant statistinius absoliutinės paklaidos rodiklius, modelio spėjimai buvo konvertuoti į originalų duomenų mastelį. Taigi atsižvelgus, kad tyrimo metu duomenys buvo apibrėžiami sferos funkcija, maksimali galima absoliutinė paklaida šio tyrimo atveju yra 100.

        \subsubsection{Sferos funkcija, kai k = 1}

            \input{skyriai/praktine_dalis/knn/nn_rodikliai_0}
            \input{skyriai/praktine_dalis/knn/nn_rodikliai_1}
            \input{skyriai/praktine_dalis/knn/nn_palyginimas}

        \subsubsection{Sferos funkcija, kai k = 3}

            \input{skyriai/praktine_dalis/knn/knn_rodikliai_0}
            \input{skyriai/praktine_dalis/knn/knn_rodikliai_1}
            \input{skyriai/praktine_dalis/knn/knn_palyginimas}

        \subsubsection{K artimiausių kaimynų metodo rezultatų palyginimas}

            Palyginus metodo rezultatus, kai $k = 1$ ir $k = 3$ yra akivaizdu, kad su didesniu kaimynų kiekiu, modelis grąžina geresnius rezultatus. Taip pat matome, kad abiem atvejais, modelių grąžinami rezultatai stabiliai gerėjo.
