\section{Dirbtinių neuroninių tinklų sandara}
\label{skr:dnt_sandara}

    Dirbtiniai neuroniniai tinklai yra sudaryti iš tarpusavyje sujungtų neuronų, sudarančių tinklą. Žemiau pateiktas \ref{pav:dnt} paveikslėlis iliustruoja dirbtinių neuroninių tinklų sandarą.

    \begin{figure}[H]
        \centering
        \includegraphics[width=0.5\linewidth]{attachments/img/dnt.jpg}
        \caption{Dirbtinių neuroninių tinklų sandara}
        \label{pav:dnt}
    \end{figure}

    Toliau einantys \ref{skr:neuronai}, \ref{skr:sluoksniai} poskyriai detaliau apžvelgia dirbtinių neuroninių tinklų sudedamąsias dalis ir jų prasmę.

    \subsection{Neuronai}
    \label{skr:neuronai}

        Neuronas dirbtiniuose neuroniniuose tinkluose yra pagrindinė sudedamoji - tai apdorojimo vienetas (angl. \enquote{processing unit}), priimantis įvestį iš vienų neuronų ir generuojantis išvestį kitiems. Neuronai yra atsakingi už skaičiavimus, kurie padeda modeliui išgryninti sąryšį tarp duomenų įvesties ir numatomos išvesties. Šiai užduočiai atlikti neuronai pasitelkia svertinės sumos ir aktyvavimo funkcijas. Apie jas plačiau galima rasti atitinkamai \ref{skr:svertine_suma} bei \ref{skr:aktyvavimo_funkc} poskyriuose.

        Žemiau pateiktas \ref{pav:dnt_neuronas} paveikslėlis iliustruoja neurono paskirtį dirbtiniuose neuroniniuose tinkluose.

        \begin{figure}[H]
            \centering
            \includegraphics[width=0.5\linewidth]{attachments/img/dnt_neuronas.jpg}
            \caption{Neurono paskirtis dirbtiniuose neuroniniuose tinkluose}
            \label{pav:dnt_neuronas}
        \end{figure}

        \subsubsection{Svertinės sumos funkcija}
        \label{skr:svertine_suma}

            Kaip jau buvo minėta neuronai tarpusavyje yra sujungti ir taip sudaro tinklą. Kiekviena jungtis tarp neuronų yra apibūdinama svoriu - skaitine reikšme, nusakančia, kokio dydžio įtaką vienas neuronas turi kitam. Šios reikšmės yra naudojamos svertinės sumos funkcijos reikšmei apskaičiuoti, kurios pavidalas yra
            \begin{equation}
                \label{eq:svertines_sumos_funkc}
                z = \sum_{i=0}^{n} x_i \cdot w_i + b
            \end{equation}
            Čia $z$ - svertinės sumos reikšmė, $x_i$ - i-ojo neurono įvestis nagrinėjama neuronui, $w_i$ - i-ojo neurono svoris, susijęs su nagrinėjamu neuronu, $b$ - šališkumo (angl. \enquote{bias}) reikšmė.

            Ši funkcija yra reikalinga tam, kad neuronas galėtų apibendrinti visas gautas įvestis į vieną skaitinę vertę, kuri vėliau perduodama aktyvavimo funkcijai, jei ji yra naudojama, arba kitam neuronų sluoksniui.

        \subsubsection{Aktyvavimo funkcijos}
        \label{skr:aktyvavimo_funkc}

            Dirbtiniai neuroniniai tinklai taikomi ne tik su tiesiniais, bet ir su netiesines savybes turinčiais duomenim. Jei modeliai naudotų vien svertinės sumos funkcijos apskaičiavimus, jie generuotų tik tiesines išvestis ir nebūtų tinkami atpažinti sudėtingesnius duomenų raštus. Siekiant įveikti šį apribojimą, neuroniniuose tinkluose yra naudojamos aktyvavimo funkcijos.

            Aktyvavimo funkcijos pasirinkimas priklauso nuo sprendžiamo uždavinio specifikos. Žemiau pateiktos \ref{eq:aktyvavimo_funkc_sigmoidine}, \ref{eq:aktyvavimo_funkc_hiperbolinio_tangento}, \ref{eq:aktyvavimo_funkc_relu} funkcijos yra dažniausiai neuroniniuose tinkluose naudojamos aktyvavimo funkcijos.

            \paragraph{Sigmoidinė funkcija}

                \begin{equation}
                    \label{eq:aktyvavimo_funkc_sigmoidine}
                    \sigma(x) = \frac{1}{1 + e^{-x}}
                \end{equation}

            \paragraph{Hiperbolinio tangento funkcija}
            
                \begin{equation}
                    \label{eq:aktyvavimo_funkc_hiperbolinio_tangento}
                    f(x) = \tanh(x) = \frac{e^x - e^-x}{e^x + e^-x}
                \end{equation}

            \paragraph{Rektifikuoto tiesinio elemento funkcija}
            
                \begin{equation}
                    \label{eq:aktyvavimo_funkc_relu}
                    \text{ReLU}(x) =
                    \begin{cases}
                        0, \text{ jei $x \leq 0$ } \\ 
                        x, \text{ jei $x > 0$ }
                    \end{cases}
                \end{equation}

    \subsection{Sluoksniai dirbtiniuose neuroniniuose tinkluose}
    \label{skr:sluoksniai}

        Dirbtiniai neuroniniai tinklai išsiskiria nuo kitų mašininio mokymosi metodų savo architektūra - neuronų tinklas yra sudarytas sluoksniais. Dažniausiai dirbtinius neuroninius tinklus sudaro vienas įvesties, vienas ar keli paslėptieji ir vienas išvesties sluoksnis.

        Žemiau pateiktas \ref{pav:dnt_sluoksniai} paveikslėlis iliustruoja dirbtinių neuroninių tinklų sandarą atsižvelgiant į neuronų sluoksnius.

        \begin{figure}[H]
            \centering
            \includegraphics[width=0.6\linewidth]{attachments/img/dnt_sluoksniai.jpg}
            \caption{Dirbtinių neuroninių tinklų sluoksniai}
            \label{pav:dnt_sluoksniai}
        \end{figure}

        \paragraph{Įviesties sluosknis}
            
            Įvesties sluoksnis dirbtiniuose neuroniniuose tinkluose yra atsakingas už duomenų surinkimą. Neuronų skaičius šiame sluoksnyje priklauso nuo to, kokios dimensijos duomenys yra nagrinėjami, neįskaitant klasės ar spėjamos reikšmės. Taip, pavyzdžiui, turint duomenis su dviem požymiais, įvesties sluoksnyje bus du neuronai. Tuo tarpu turint šešių dimensijų duomenis, neuronų įvesties sluoksnyje bus šeši.

        \paragraph{Išvesties sluosknis}
            
            Išvesties sluoksnis dirbtiniuose neuroniniuose tinkluose yra naudojamas modelio rezultatams generuoti. Neuronų kiekis šiame sluoksnyje priklauso nuo sprendžiamos užduoties tipo. Klasifikavimo uždaviniuose išvesties sluoksnio neuronų skaičius paprastai sutampa su galimų klasių skaičiumi, o kiekvieno neurono išvestis interpretuojama kaip tikimybė, kad įvesties duomenys priklauso tai klasei. Tuo tarpu regresijos uždaviniuose dažniausiai naudojamas vienas neuronas, kurio išvestis atitinka prognozuojamą reikšmę.
        
        \paragraph{Paslėptasis sluoksnis}

            Paslėptieji sluoksniai dirbtiniuose neuroniniuose tinkluose yra skirti matematinių ryšių tarp įvesties ir išvesties nustatymui. Šiuose sluoksniuose esančių neuronų kiekis yra hiperparametras - jis yra parenkamas eksperimentiškai, analizuojant, su kuria reikšme modelis pasirodo geriausiai validacijos metu.
