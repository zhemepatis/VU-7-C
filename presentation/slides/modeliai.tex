\section{Modeliai}

    \begin{frame}[allowframebreaks]{Dirbtinio neuroninio tinklo modelis}

        \begin{itemize}
            
            \item Dirbtinio neuroninio tinklo modelis buvo sudarytas iš vieno įvesties sluoksnio (4 neuronai), vieno paslėpto sluoksnio (70 neuronų) bei vieno išvesties sluoksnio (1 neuronas). 
            
            \item Paslėptajame sluoksnyje buvo panaudota sigmoidinė aktyvavimo funkcija, tuo tarpu išvesties sluoksnyje aktyvavimo funkcija pritaikyta nebuvo. 
            
            \item Ši architektūra buvo pasirinkta remiantis teorema, teigiančia, kad bet kuri tolydi funkcija gali būti aproksimuota dirbtiniu neuroniniu tinklu, turinčiu vieną paslėptą sluoksnį su netiesine sigmoidine aktyvavimo funkcija \cite{cybenko_aproximation}. 

            \break

            \item Modelio mokymosi ilgio reikšmė buvo lygi $0,01$, o mokymosi aibė buvo padalinta į dalis po 8 įrašus. Modelio apmokymo etapas buvo stabdomas įvykus vienai iš stabdymo sąlygų:
            
            \begin{itemize}
                \item klaidos funkcijos reikšmė $13$ epochų iš eilės mažėja mažiau nei per $10^{-6}$;
                \item buvo pasiektas maksimalus $150$ epochų kiekis.
            \end{itemize}

            \item Modelio apmokymui buvo skiriama $70\%$ aibės duomenų, $15\%$ buvo skiriama modelio validavimui, ir kiti $15\%$ - modelio testavimui. 

        \end{itemize}
        
    \end{frame}

    \begin{frame}{$k$ artimiausių kaimynų modeliai}

        \begin{itemize}
            
            \item $k$ artimiausių kaimynų metodas buvo išbandytas su parametro reikšmėm $k = 1$ ir $k = 3$. 
            
            \item 85\% kiekvienos duomenų aibės įrašų buvo skiriami duomenų saugojimui ir validavimui, o likę 15\% -- modelio testavimui.
        \end{itemize}
        
    \end{frame}